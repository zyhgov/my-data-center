import { Octokit } from '@octokit/rest';
import { fileToBase64, getFolderByType, generateFileName } from '../utils/fileHelper';
import { splitFileIntoChunks, blobToBase64, getChunkPath } from '../utils/chunkHelper';

// åˆå§‹åŒ– Octokit
const octokit = new Octokit({
  auth: import.meta.env.VITE_GITHUB_TOKEN
});

const REPO_CONFIG = {
  owner: import.meta.env.VITE_GITHUB_OWNER,
  repo: import.meta.env.VITE_STORAGE_REPO
};

// æ–‡ä»¶å¤§å°é™åˆ¶
const DIRECT_UPLOAD_LIMIT = 20 * 1024 * 1024; // 20MB - ç›´æ¥ä¸Šä¼ 
const MAX_FILE_SIZE = 2 * 1024 * 1024 * 1024; // 2GB - æœ€å¤§æ”¯æŒ

// æ£€æŸ¥é…ç½®
if (!import.meta.env.VITE_GITHUB_TOKEN || !REPO_CONFIG.owner || !REPO_CONFIG.repo) {
  console.error('âŒ GitHub é…ç½®ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥ .env.local æ–‡ä»¶');
}

export const githubService = {
  
  // ============================================
  // ç›´æ¥ä¸Šä¼ ï¼ˆå°æ–‡ä»¶ <20MBï¼‰
  // ============================================
  async uploadDirect(file, options = {}) {
    try {
      const { onProgress = null } = options;

      const folder = getFolderByType(file.type, file.name);
      const filename = generateFileName(file.name);
      const path = `${folder}/${filename}`;

      console.log('ğŸ“¤ ç›´æ¥ä¸Šä¼ :', file.name, 'â†’', path);
      onProgress?.(10);

      const content = await fileToBase64(file);
      onProgress?.(50);

      const response = await octokit.repos.createOrUpdateFileContents({
        ...REPO_CONFIG,
        path,
        message: `Upload ${file.name}`,
        content,
        committer: {
          name: 'Data Center Bot',
          email: 'bot@data-center.com'
        }
      });

      onProgress?.(90);
      console.log('âœ… ä¸Šä¼ æˆåŠŸ:', response.data.content.path);

      await this.triggerWorkflow();
      onProgress?.(100);

      return {
        success: true,
        originalName: file.name,
        originalFile: file,
        path: response.data.content.path,
        sha: response.data.content.sha,
        commitSha: response.data.commit.sha,
        githubUrl: response.data.content.html_url,
        cdnUrl: this.getCDNUrl(path),
        isChunked: false,
        chunkCount: 1,
        chunkPaths: [path]
      };

    } catch (error) {
      console.error('âŒ ç›´æ¥ä¸Šä¼ å¤±è´¥:', error);
      throw new Error(`ä¸Šä¼ å¤±è´¥: ${error.message}`);
    }
  },

  // ============================================
  // åˆ†å—ä¸Šä¼ ï¼ˆå¤§æ–‡ä»¶ 20MB-2GBï¼‰
  // ============================================
  async uploadChunked(file, options = {}) {
    try {
      const { onProgress = null } = options;

      console.log('ğŸ“¦ å¼€å§‹åˆ†å—ä¸Šä¼ :', file.name);
      onProgress?.(5);

      // åˆ†å—
      const { chunks, totalChunks } = await splitFileIntoChunks(file);
      console.log(`ğŸ“Š åˆ†ä¸º ${totalChunks} å—`);

      const folder = getFolderByType(file.type, file.name);
      const filename = generateFileName(file.name);
      const basePath = `${folder}/${filename}`;

      // è·å–å½“å‰ commit
      const { data: ref } = await octokit.git.getRef({
        ...REPO_CONFIG,
        ref: 'heads/main'
      });

      const { data: commit } = await octokit.git.getCommit({
        ...REPO_CONFIG,
        commit_sha: ref.object.sha
      });

      onProgress?.(10);

      // åˆ›å»ºæ‰€æœ‰ blobs
      const blobs = [];
      const chunkPaths = [];
      const chunkSHAs = []; // ä¿å­˜æ¯ä¸ªåˆ†å—çš„ SHA

      for (let i = 0; i < chunks.length; i++) {
        const chunk = chunks[i];
        const chunkPath = getChunkPath(basePath, i, totalChunks);
        chunkPaths.push(chunkPath);

        console.log(`ğŸ“„ å¤„ç†åˆ†å— ${i + 1}/${totalChunks}:`, chunkPath);

        const content = await blobToBase64(chunk.blob);

        const { data: blob } = await octokit.git.createBlob({
          ...REPO_CONFIG,
          content,
          encoding: 'base64'
        });

        blobs.push({
          path: chunkPath,
          mode: '100644',
          type: 'blob',
          sha: blob.sha
        });

        chunkSHAs.push(blob.sha); // è®°å½• SHA

        const progress = 10 + ((i + 1) / totalChunks) * 70;
        onProgress?.(progress);
      }

      onProgress?.(80);
      console.log('âœ… æ‰€æœ‰åˆ†å— blob åˆ›å»ºå®Œæˆ');

      // åˆ›å»º tree
      const { data: tree } = await octokit.git.createTree({
        ...REPO_CONFIG,
        base_tree: commit.tree.sha,
        tree: blobs
      });

      onProgress?.(85);

      // åˆ›å»º commit
      const { data: newCommit } = await octokit.git.createCommit({
        ...REPO_CONFIG,
        message: `Upload chunked file: ${file.name} (${totalChunks} parts)`,
        tree: tree.sha,
        parents: [ref.object.sha],
        committer: {
          name: 'Data Center Bot',
          email: 'bot@data-center.com'
        }
      });

      onProgress?.(90);

      // æ›´æ–°å¼•ç”¨
      await octokit.git.updateRef({
        ...REPO_CONFIG,
        ref: 'heads/main',
        sha: newCommit.sha
      });

      onProgress?.(95);
      console.log('âœ… åˆ†å—ä¸Šä¼ å®Œæˆï¼');

      await this.triggerWorkflow();
      onProgress?.(100);

      return {
        success: true,
        originalName: file.name,
        originalFile: file,
        path: basePath,
        sha: newCommit.sha,
        commitSha: newCommit.sha,
        githubUrl: `https://github.com/${REPO_CONFIG.owner}/${REPO_CONFIG.repo}/tree/main/${folder}`,
        cdnUrl: null,
        isChunked: true,
        chunkCount: totalChunks,
        chunkPaths: chunkPaths,
        chunkSHAs: chunkSHAs // ğŸ”¥ æ–°å¢ï¼šä¿å­˜ SHA æ•°ç»„
      };

    } catch (error) {
      console.error('âŒ åˆ†å—ä¸Šä¼ å¤±è´¥:', error);
      throw new Error(`åˆ†å—ä¸Šä¼ å¤±è´¥: ${error.message}`);
    }
  },

  // ============================================
  // å•æ–‡ä»¶ä¸Šä¼ ï¼ˆæ™ºèƒ½é€‰æ‹©ï¼‰
  // ============================================
  async uploadSingleFile(file, options = {}) {
    if (file.size > MAX_FILE_SIZE) {
      throw new Error(`æ–‡ä»¶è¿‡å¤§ï¼ˆ${(file.size / 1024 / 1024 / 1024).toFixed(2)}GBï¼‰ï¼Œæœ€å¤§æ”¯æŒ 2GB`);
    }

    if (file.size > DIRECT_UPLOAD_LIMIT) {
      console.log(`ğŸ“¦ åˆ†å—æ¨¡å¼: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)}MB)`);
      return await this.uploadChunked(file, options);
    } else {
      console.log(`ğŸ“„ ç›´æ¥æ¨¡å¼: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)}MB)`);
      return await this.uploadDirect(file, options);
    }
  },

  // ============================================
  // æ‰¹é‡æ–‡ä»¶ä¸Šä¼ 
  // ============================================
  async uploadMultipleFiles(files, options = {}) {
    try {
      const { onProgress = null } = options;
      
      console.log(`ğŸ“¦ å¼€å§‹æ‰¹é‡ä¸Šä¼  ${files.length} ä¸ªæ–‡ä»¶...`);
      
      const directFiles = files.filter(f => f.size <= DIRECT_UPLOAD_LIMIT);
      const chunkedFiles = files.filter(f => f.size > DIRECT_UPLOAD_LIMIT && f.size <= MAX_FILE_SIZE);
      const tooLargeFiles = files.filter(f => f.size > MAX_FILE_SIZE);

      if (tooLargeFiles.length > 0) {
        const names = tooLargeFiles.map(f => f.name).join(', ');
        throw new Error(`ä»¥ä¸‹æ–‡ä»¶è¶…è¿‡ 2GB é™åˆ¶ï¼š${names}`);
      }

      console.log(`ğŸ“Š ç›´æ¥ä¸Šä¼ : ${directFiles.length}ï¼Œåˆ†å—ä¸Šä¼ : ${chunkedFiles.length}`);

      const allResults = [];
      let totalProgress = 0;
      const totalFiles = directFiles.length + chunkedFiles.length;

      // 1. æ‰¹é‡ä¸Šä¼ å°æ–‡ä»¶
      if (directFiles.length > 0) {
        console.log(`ğŸ“¤ æ‰¹é‡ä¸Šä¼  ${directFiles.length} ä¸ªå°æ–‡ä»¶...`);
        onProgress?.(5);

        const { data: ref } = await octokit.git.getRef({
          ...REPO_CONFIG,
          ref: 'heads/main'
        });

        const { data: commit } = await octokit.git.getCommit({
          ...REPO_CONFIG,
          commit_sha: ref.object.sha
        });

        const blobs = [];
        const fileInfos = [];

        for (let i = 0; i < directFiles.length; i++) {
          const file = directFiles[i];
          const folder = getFolderByType(file.type, file.name);
          const filename = generateFileName(file.name);
          const path = `${folder}/${filename}`;

          console.log(`ğŸ“„ å¤„ç†æ–‡ä»¶ ${i + 1}/${directFiles.length}:`, file.name);

          const content = await fileToBase64(file);

          const { data: blob } = await octokit.git.createBlob({
            ...REPO_CONFIG,
            content,
            encoding: 'base64'
          });

          blobs.push({
            path,
            mode: '100644',
            type: 'blob',
            sha: blob.sha
          });

          fileInfos.push({
            originalFile: file,
            path,
            sha: blob.sha
          });

          totalProgress++;
          onProgress?.((totalProgress / totalFiles) * 60);
        }

        const { data: tree } = await octokit.git.createTree({
          ...REPO_CONFIG,
          base_tree: commit.tree.sha,
          tree: blobs
        });

        const { data: newCommit } = await octokit.git.createCommit({
          ...REPO_CONFIG,
          message: `Upload ${directFiles.length} files`,
          tree: tree.sha,
          parents: [ref.object.sha],
          committer: {
            name: 'Data Center Bot',
            email: 'bot@data-center.com'
          }
        });

        await octokit.git.updateRef({
          ...REPO_CONFIG,
          ref: 'heads/main',
          sha: newCommit.sha
        });

        console.log('âœ… å°æ–‡ä»¶æ‰¹é‡ä¸Šä¼ å®Œæˆ');

        allResults.push(...fileInfos.map(info => ({
          originalName: info.originalFile.name,
          originalFile: info.originalFile,
          path: info.path,
          sha: info.sha,
          githubUrl: `https://github.com/${REPO_CONFIG.owner}/${REPO_CONFIG.repo}/blob/main/${info.path}`,
          cdnUrl: this.getCDNUrl(info.path),
          isChunked: false,
          chunkCount: 1,
          chunkPaths: [info.path]
        })));
      }

      // 2. é€ä¸ªä¸Šä¼ å¤§æ–‡ä»¶ï¼ˆåˆ†å—ï¼‰
      if (chunkedFiles.length > 0) {
        console.log(`ğŸ“¦ é€ä¸ªä¸Šä¼  ${chunkedFiles.length} ä¸ªå¤§æ–‡ä»¶...`);
        
        for (let i = 0; i < chunkedFiles.length; i++) {
          const file = chunkedFiles[i];
          console.log(`ğŸ“¦ ä¸Šä¼ å¤§æ–‡ä»¶ ${i + 1}/${chunkedFiles.length}:`, file.name);

          const result = await this.uploadChunked(file, {
            onProgress: (progress) => {
              const baseProgress = 60 + ((totalProgress + progress / 100) / totalFiles) * 30;
              onProgress?.(baseProgress);
            }
          });

          allResults.push(result);
          totalProgress++;
        }

        console.log('âœ… å¤§æ–‡ä»¶ä¸Šä¼ å®Œæˆ');
      }

      await this.triggerWorkflow();
      onProgress?.(100);

      return {
        success: true,
        commitSha: null,
        files: allResults
      };

    } catch (error) {
      console.error('âŒ æ‰¹é‡ä¸Šä¼ å¤±è´¥:', error);
      throw new Error(`æ‰¹é‡ä¸Šä¼ å¤±è´¥: ${error.message}`);
    }
  },

  // ============================================
  // æ™ºèƒ½ä¸Šä¼ å…¥å£
  // ============================================
  async uploadFiles(files, options = {}) {
    const fileArray = Array.isArray(files) ? files : [files];

    if (fileArray.length === 0) {
      throw new Error('æ²¡æœ‰æ–‡ä»¶éœ€è¦ä¸Šä¼ ');
    }

    const tooLarge = fileArray.filter(f => f.size > MAX_FILE_SIZE);
    if (tooLarge.length > 0) {
      const names = tooLarge.map(f => `${f.name} (${(f.size / 1024 / 1024 / 1024).toFixed(2)}GB)`).join(', ');
      throw new Error(`ä»¥ä¸‹æ–‡ä»¶è¶…è¿‡ 2GB é™åˆ¶ï¼š${names}`);
    }

    if (fileArray.length === 1) {
      console.log('ğŸ“¤ å•æ–‡ä»¶ä¸Šä¼ æ¨¡å¼');
      const result = await this.uploadSingleFile(fileArray[0], options);
      return {
        success: true,
        commitSha: result.commitSha,
        files: [result]
      };
    }

    console.log(`ğŸ“¦ æ‰¹é‡ä¸Šä¼ æ¨¡å¼ (${fileArray.length} ä¸ªæ–‡ä»¶)`);
    return await this.uploadMultipleFiles(fileArray, options);
  },

  // ============================================
  // ä¸‹è½½åˆ†å—æ–‡ä»¶ï¼ˆä½¿ç”¨ Blob API - æœ€ç¨³å®šï¼‰
  // ============================================
  async downloadChunkedFile(chunkPaths, chunkSHAs, mimeType, originalName, onProgress = null) {
    try {
      console.log(`ğŸ“¥ å¼€å§‹ä¸‹è½½åˆ†å—æ–‡ä»¶: ${originalName} (${chunkPaths.length} å—)`);
      
      const chunks = [];
      
      // ğŸ”¥ ä¼˜å…ˆä½¿ç”¨ SHA ä¸‹è½½ï¼ˆå¦‚æœæœ‰ï¼‰
      const useSHA = chunkSHAs && chunkSHAs.length === chunkPaths.length;
      
      for (let i = 0; i < chunkPaths.length; i++) {
        const path = chunkPaths[i];
        console.log(`ğŸ“¥ ä¸‹è½½åˆ†å— ${i + 1}/${chunkPaths.length}:`, path);
        
        try {
          let blobSHA = useSHA ? chunkSHAs[i] : null;
          
          // å¦‚æœæ²¡æœ‰ SHAï¼Œå…ˆè·å–æ–‡ä»¶ä¿¡æ¯
          if (!blobSHA) {
            console.log('ğŸ” è·å–æ–‡ä»¶ SHA...');
            const { data: fileInfo } = await octokit.repos.getContent({
              ...REPO_CONFIG,
              path,
              ref: 'main'
            });
            blobSHA = fileInfo.sha;
          }
          
          console.log(`ğŸ”‘ ä½¿ç”¨ SHA: ${blobSHA.substring(0, 7)}...`);
          
          // ğŸ”¥ ä½¿ç”¨ Blob API ç›´æ¥è·å–å†…å®¹ï¼ˆé€šè¿‡ SHAï¼‰
          const { data: blobData } = await octokit.git.getBlob({
            ...REPO_CONFIG,
            file_sha: blobSHA
          });
          
          console.log(`ğŸ“¦ è·å–åˆ° Blob:`, {
            encoding: blobData.encoding,
            size: blobData.size
          });
          
          if (!blobData.content) {
            throw new Error(`åˆ†å— ${path} å†…å®¹ä¸ºç©º`);
          }
          
          // Base64 è§£ç ï¼ˆæ¸…ç†æ‰€æœ‰ç©ºç™½å­—ç¬¦ï¼‰
          const cleanedContent = blobData.content.replace(/\s/g, '');
          const binaryString = atob(cleanedContent);
          const bytes = new Uint8Array(binaryString.length);
          
          for (let j = 0; j < binaryString.length; j++) {
            bytes[j] = binaryString.charCodeAt(j);
          }
          
          chunks.push(bytes);
          
          console.log(`âœ… åˆ†å— ${i + 1} ä¸‹è½½å®Œæˆï¼Œå¤§å°: ${bytes.length} å­—èŠ‚`);
          
          const currentProgress = ((i + 1) / chunkPaths.length) * 100;
          onProgress?.(currentProgress);
          
        } catch (chunkError) {
          console.error(`âŒ ä¸‹è½½åˆ†å— ${path} å¤±è´¥:`, chunkError);
          throw new Error(`ä¸‹è½½åˆ†å— ${i + 1} å¤±è´¥: ${chunkError.message}`);
        }
      }
      
      // åˆå¹¶åˆ†å—
      const totalSize = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
      console.log(`ğŸ“¦ å¼€å§‹åˆå¹¶ï¼Œæ€»å¤§å°: ${totalSize} å­—èŠ‚`);
      
      const mergedArray = new Uint8Array(totalSize);
      let offset = 0;
      
      for (const chunk of chunks) {
        mergedArray.set(chunk, offset);
        offset += chunk.length;
      }
      
      const blob = new Blob([mergedArray], { type: mimeType });
      console.log(`âœ… åˆ†å—æ–‡ä»¶åˆå¹¶å®Œæˆï¼Œæœ€ç»ˆå¤§å°: ${blob.size} å­—èŠ‚`);
      
      return blob;
    } catch (error) {
      console.error('âŒ ä¸‹è½½åˆ†å—æ–‡ä»¶å¤±è´¥:', error);
      throw error;
    }
  },

  // ============================================
  // åˆ é™¤æ–‡ä»¶ï¼ˆå…¼å®¹åˆ†å—ï¼‰
  // ============================================
  async deleteFile(path, sha, isChunked = false, chunkPaths = []) {
    try {
      if (isChunked && chunkPaths.length > 0) {
        console.log(`ğŸ—‘ï¸ åˆ é™¤åˆ†å—æ–‡ä»¶ (${chunkPaths.length} å—)`);
        
        for (const chunkPath of chunkPaths) {
          try {
            const { data: fileData } = await octokit.repos.getContent({
              ...REPO_CONFIG,
              path: chunkPath
            });
            
            await octokit.repos.deleteFile({
              ...REPO_CONFIG,
              path: chunkPath,
              message: `Delete chunk: ${chunkPath}`,
              sha: fileData.sha
            });
            
            console.log(`âœ… å·²åˆ é™¤åˆ†å—: ${chunkPath}`);
          } catch (error) {
            console.warn(`âš ï¸ åˆ é™¤åˆ†å—å¤±è´¥: ${chunkPath}`, error);
          }
        }
      } else {
        await octokit.repos.deleteFile({
          ...REPO_CONFIG,
          path,
          message: `Delete ${path}`,
          sha
        });
        console.log(`âœ… å·²åˆ é™¤æ–‡ä»¶: ${path}`);
      }
      
      await this.triggerWorkflow();
      
      return { success: true };
    } catch (error) {
      console.error('åˆ é™¤æ–‡ä»¶å¤±è´¥:', error);
      throw error;
    }
  },

  // ============================================
  // è§¦å‘ GitHub Actions Workflow
  // ============================================
  async triggerWorkflow() {
    try {
      await octokit.repos.createDispatchEvent({
        ...REPO_CONFIG,
        event_type: 'deploy-pages',
        client_payload: {
          timestamp: new Date().toISOString()
        }
      });
      
      console.log('âœ… å·²è§¦å‘ GitHub Pages éƒ¨ç½²');
      return { success: true };
    } catch (error) {
      console.warn('âš ï¸ è§¦å‘éƒ¨ç½²å¤±è´¥ï¼Œä½†æ–‡ä»¶å·²ä¸Šä¼ :', error.message);
      return { success: false, error: error.message };
    }
  },

  // ============================================
  // è·å– Workflow è¿è¡ŒçŠ¶æ€
  // ============================================
  async getWorkflowRunStatus(commitSha) {
    try {
      const { data } = await octokit.actions.listWorkflowRunsForRepo({
        ...REPO_CONFIG,
        per_page: 5
      });

      const run = data.workflow_runs[0];
      
      if (!run) {
        return {
          status: 'pending',
          conclusion: null,
          url: null
        };
      }
      
      return {
        status: run.status,
        conclusion: run.conclusion,
        url: run.html_url,
        runId: run.id,
        createdAt: run.created_at,
        updatedAt: run.updated_at
      };

    } catch (error) {
      console.error('âŒ è·å– workflow çŠ¶æ€å¤±è´¥:', error);
      return {
        status: 'unknown',
        conclusion: null,
        url: null,
        error: error.message
      };
    }
  },

  // ============================================
  // è½®è¯¢ Workflow çŠ¶æ€
  // ============================================
  async waitForDeployment(commitSha, onStatusChange = null) {
    const maxAttempts = 60;
    let attempts = 0;

    return new Promise((resolve, reject) => {
      const checkStatus = async () => {
        attempts++;
        
        try {
          const status = await this.getWorkflowRunStatus(commitSha);
          
          console.log(`ğŸ”„ æ„å»ºçŠ¶æ€æ£€æŸ¥ (${attempts}/${maxAttempts}):`, status.status, status.conclusion);
          
          onStatusChange?.(status);

          if (status.status === 'completed') {
            if (status.conclusion === 'success') {
              console.log('âœ… éƒ¨ç½²æˆåŠŸï¼');
              resolve(status);
            } else {
              console.log('âŒ éƒ¨ç½²å¤±è´¥:', status.conclusion);
              reject(new Error(`éƒ¨ç½²å¤±è´¥: ${status.conclusion}`));
            }
            return;
          }

          if (attempts >= maxAttempts) {
            console.log('â° ç­‰å¾…è¶…æ—¶');
            resolve({
              ...status,
              timeout: true
            });
            return;
          }

          setTimeout(checkStatus, 5000);

        } catch (error) {
          console.error('âŒ æ£€æŸ¥çŠ¶æ€å¤±è´¥:', error);
          reject(error);
        }
      };

      setTimeout(checkStatus, 10000);
    });
  },

  // ============================================
  // ç”Ÿæˆ CDN é“¾æ¥
  // ============================================
  getCDNUrl(path) {
    const customDomain = import.meta.env.VITE_CDN_DOMAIN;
    
    if (customDomain) {
      return `https://${customDomain}/${path}`;
    } else {
      return `https://cdn.jsdelivr.net/gh/${REPO_CONFIG.owner}/${REPO_CONFIG.repo}@main/${path}`;
    }
  },

  // ============================================
  // æµ‹è¯•è¿æ¥
  // ============================================
  async testConnection() {
    try {
      const { data } = await octokit.repos.get({
        ...REPO_CONFIG
      });
      console.log('âœ… GitHub è¿æ¥æˆåŠŸ:', data.full_name);
      return {
        success: true,
        repo: data.full_name,
        size: data.size,
        private: data.private
      };
    } catch (error) {
      console.error('âŒ GitHub è¿æ¥å¤±è´¥:', error);
      return {
        success: false,
        error: error.message
      };
    }
  }
};